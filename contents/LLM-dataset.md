## LLM base data

| Dataset       | Size       | Year          | Description                                                                                     |
|---------------|------------|---------------|-------------------------------------------------------------------------------------------------|
| Common Crawl  | 250 TB     | 2008-present  | A collection of raw web data extracted from billions of web pages                                |
| C4            | 750 GB     | 2020          | A cleaned and deduplicated subset of Common Crawl, containing about 13.5 billion sentences       |
| The Pile      | 825 GB     | 2020          | A diverse set of 22 smaller datasets, covering various domains such as books, news, code, etc.   |
| Wikipedia     | 16 GB      | 2001-present  | A free online encyclopedia that anyone can edit                                                  |
| BookCorpus    | 6 GB       | 2015          | A corpus of 11,038 books from various genres                                                     |

- C4 dataset contains about 13.5 billion sentences, of which 87.3% are in English.
